{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir already exists at C:\\Users\\Dylan\\Desktop/aclImdb.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "# import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# extract_dir = '/Users/dylanjfox/Desktop'\n",
    "extract_dir = r'C:\\Users\\Dylan\\Desktop'\n",
    "\n",
    "def extract_tar_gz(file_path, extract_path=extract_dir):\n",
    "    with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "        print(f\"Extracted to {extract_path}...\")\n",
    "\n",
    "if not os.path.exists(f\"{extract_dir}/aclImdb\"):\n",
    "    extract_tar_gz(\"aclImdb_v1.tar.gz\", extract_dir)\n",
    "else:\n",
    "    print(f\"Dir already exists at {extract_dir}/aclImdb.\")\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "negative_words = ['not', 'never', 'dont', 'didnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "word_counts = {}\n",
    "\n",
    "def pull_words(folder_path):\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # print(f'Processing file: {file_path}')\n",
    "            with open(file_path, 'r') as file:\n",
    "                words = file.read().lower().split()\n",
    "\n",
    "                i = 0\n",
    "                while i < len(words):\n",
    "                    word = re.sub(r\"[^\\w\\s]\", \"\", words[i])\n",
    "                    \n",
    "                    if word in negative_words and i + 1 < len(words):\n",
    "                        combined_word = f\"{word}_{words[i + 1]}\" \n",
    "                        \n",
    "                        if combined_word in word_counts:\n",
    "                            word_counts[combined_word] += 1\n",
    "                        else:\n",
    "                            word_counts[combined_word] = 1\n",
    "                        i += 2  \n",
    "                    else:\n",
    "                        if word in word_counts:\n",
    "                            word_counts[word] += 1\n",
    "                        else:\n",
    "                            word_counts[word] = 1\n",
    "                        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [r'C:\\Users\\Dylan\\Desktop\\aclImdb\\test\\pos', \n",
    "            r'C:\\Users\\Dylan\\Desktop\\aclImdb\\test\\neg', \n",
    "            r'C:\\Users\\Dylan\\Desktop\\aclImdb\\train\\pos', \n",
    "            r'C:\\Users\\Dylan\\Desktop\\aclImdb\\train\\neg']\n",
    "\n",
    "\n",
    "if not os.path.exists(r\"C:\\Users\\Dylan\\Desktop\\ml432\\projects\\sentiment_analysis\\word_counts.json\"):\n",
    "    for dir in dir_list:\n",
    "        pull_words(dir)\n",
    "else:\n",
    "    with open('word_counts.json', 'r') as file:\n",
    "        word_counts = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 661228\n",
      "and: 320505\n",
      "a: 316454\n",
      "of: 288289\n",
      "to: 264024\n",
      "...\n",
      "submarinebr: 1\n",
      "irreversiblestyle: 1\n",
      "americancanadian: 1\n",
      "lasciviousdecadent: 1\n",
      "whelkbr: 1\n"
     ]
    }
   ],
   "source": [
    "s_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "for word, count in list(s_word_counts.items())[:5]:\n",
    "    print(f'{word}: {count}')\n",
    "print(\"...\")\n",
    "for word, count in list(s_word_counts.items())[-5:]:\n",
    "    print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191688\n"
     ]
    }
   ],
   "source": [
    "print(len(s_word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  store the dictionary in a JSON file\n",
    "# with open('word_counts.json', 'w') as file:\n",
    "#     json.dump(s_word_counts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "filtered_word_counts = {word: count for word, count in s_word_counts.items() if word not in stopwords}\n",
    "\n",
    "# remove html tags\n",
    "html_tags = ['html', 'p', 'br', 'hr', '']\n",
    "\n",
    "# remove html tags\n",
    "filtered_word_counts = {word: count for word, count in filtered_word_counts.items() if word not in html_tags}\n",
    "\n",
    "movie_words = ['movie', 'movies', 'films', 'film', 'character', 'characters', 'review', 'reviews', 'one', 'two', 'show']\n",
    "\n",
    "# remove movie words\n",
    "filtered_word_counts = {word: count for word, count in filtered_word_counts.items() if word not in movie_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like: 37512\n",
      "good: 28314\n",
      "would: 23969\n",
      "time: 23255\n",
      "story: 22085\n",
      "even: 21804\n",
      "see: 21403\n",
      "really: 21039\n",
      "well: 18691\n",
      "much: 18249\n",
      "also: 17795\n",
      "great: 17669\n",
      "people: 17524\n",
      "bad: 17420\n",
      "first: 17145\n",
      "get: 16437\n",
      "made: 15184\n",
      "could: 15117\n",
      "way: 14999\n",
      "make: 14430\n",
      "many: 13238\n",
      "watch: 12749\n",
      "think: 12657\n",
      "love: 12489\n",
      "acting: 12444\n",
      "...\n",
      "191530\n"
     ]
    }
   ],
   "source": [
    "for word, count in list(filtered_word_counts.items())[:25]:\n",
    "    print(f'{word}: {count}')\n",
    "print(\"...\")\n",
    "\n",
    "print(len(filtered_word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "final_tokens = dict(list(filtered_word_counts.items())[:10000])\n",
    "\n",
    "print(len(final_tokens))\n",
    "\n",
    "with open('final_tokens.json', 'w') as file:\n",
    "    json.dump(final_tokens, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
